# ğŸ—ï¸ Arquitectura del Proyecto Titanic ML

## Ãndice

- [VisiÃ³n General](#visiÃ³n-general)
- [Diagrama de Arquitectura](#diagrama-de-arquitectura)
- [Componentes Principales](#componentes-principales)
- [Flujo de Datos](#flujo-de-datos)
- [Decisiones de DiseÃ±o](#decisiones-de-diseÃ±o)
- [Estructura de Directorios](#estructura-de-directorios)

## VisiÃ³n General

Este proyecto implementa un pipeline completo de Machine Learning para predecir la supervivencia de pasajeros del Titanic, con Ã©nfasis en buenas prÃ¡cticas de ingenierÃ­a de software, testing automatizado y CI/CD.

### Principios de DiseÃ±o

1. **Modularidad**: Cada componente tiene una responsabilidad Ãºnica y bien definida
2. **ReutilizaciÃ³n**: Los mÃ³dulos pueden usarse independientemente o en conjunto
3. **Testabilidad**: Todo el cÃ³digo estÃ¡ diseÃ±ado para ser fÃ¡cilmente testeable
4. **AutomatizaciÃ³n**: CI/CD completamente automatizado con GitHub Actions
5. **Reproducibilidad**: Semillas aleatorias fijas y versionado de modelos

## Diagrama de Arquitectura

### Arquitectura General del Sistema

```mermaid
graph TB
    subgraph "Entrada de Datos"
        DL[download_data.py]
        RAW[(data/raw)]
    end
    
    subgraph "Procesamiento"
        LOADER[data_loader.py]
        PREP[preprocessing.py]
        PROC[(data/processed)]
    end
    
    subgraph "Modelado"
        MODEL[model.py]
        TRAIN[train.py]
        MODELS[(models/)]
    end
    
    subgraph "EvaluaciÃ³n"
        EVAL[evaluate.py]
        REPORTS[(reports/)]
    end
    
    subgraph "CI/CD"
        CI[ci.yml]
        TRAIN_WF[train-model.yml]
        EVAL_WF[evaluate-model.yml]
        DOCKER_WF[docker-publish.yml]
    end
    
    subgraph "Testing"
        TESTS[tests/]
    end
    
    DL --> RAW
    RAW --> LOADER
    LOADER --> PREP
    PREP --> PROC
    PROC --> TRAIN
    MODEL --> TRAIN
    TRAIN --> MODELS
    MODELS --> EVAL
    EVAL --> REPORTS
    
    CI -.Testing.-> LOADER
    CI -.Testing.-> PREP
    CI -.Testing.-> MODEL
    CI -.Ejecuta.-> TESTS
    
    TRAIN_WF -.Ejecuta.-> DL
    TRAIN_WF -.Ejecuta.-> TRAIN
    
    EVAL_WF -.Ejecuta.-> EVAL
    EVAL_WF -.Usa.-> MODELS
    
    DOCKER_WF -.Build.-> DL
    DOCKER_WF -.Build.-> LOADER
    DOCKER_WF -.Build.-> PREP
    DOCKER_WF -.Publica.-> MODELS
    
    style DL fill:#e1f5ff
    style LOADER fill:#e1f5ff
    style PREP fill:#fff3e0
    style MODEL fill:#fff3e0
    style TRAIN fill:#e8f5e9
    style EVAL fill:#f3e5f5
    style CI fill:#fce4ec
    style TRAIN_WF fill:#fce4ec
    style EVAL_WF fill:#fce4ec
    style DOCKER_WF fill:#4A90E2
```

### Flujo del Pipeline de ML

```mermaid
sequenceDiagram
    participant User
    participant Download
    participant DataLoader
    participant Preprocessor
    participant Model
    participant Trainer
    participant Evaluator
    participant Reports
    
    User->>Download: 1. Ejecutar download_data.py
    Download->>DataLoader: Guardar datos en data/raw/
    
    User->>Trainer: 2. Ejecutar train.py
    Trainer->>DataLoader: Cargar datos raw
    DataLoader-->>Trainer: train_df, test_df
    
    Trainer->>Preprocessor: Preprocesar datos
    Preprocessor->>Preprocessor: Feature Engineering
    Preprocessor->>Preprocessor: ImputaciÃ³n
    Preprocessor->>Preprocessor: CodificaciÃ³n
    Preprocessor->>Preprocessor: Escalado
    Preprocessor-->>Trainer: X_train, y_train, X_val, y_val
    
    Trainer->>Model: Crear modelo
    Model-->>Trainer: modelo configurado
    
    Trainer->>Trainer: ValidaciÃ³n Cruzada
    Trainer->>Trainer: Entrenar modelo final
    Trainer->>Model: Guardar modelo
    Model->>Reports: Guardar mÃ©tricas
    
    User->>Evaluator: 3. Ejecutar evaluate.py
    Evaluator->>Model: Cargar modelo entrenado
    Evaluator->>DataLoader: Cargar datos
    Evaluator->>Preprocessor: Preprocesar datos de test
    Evaluator->>Evaluator: Calcular mÃ©tricas
    Evaluator->>Evaluator: Generar visualizaciones
    Evaluator->>Reports: Guardar resultados y grÃ¡ficas
    Evaluator-->>User: EvaluaciÃ³n completa
```

### Flujo de CI/CD

```mermaid
graph TB
    subgraph "Trigger Events"
        PUSH[Push/PR a main]
        MANUAL[Trigger Manual]
        SCHEDULE[Cron Semanal]
        TAG[Push Tag v*]
    end
    
    subgraph "CI Workflow"
        CHECKOUT1[Checkout Code]
        SETUP1[Setup Python 3.9-3.11]
        LINT[Linting]
        TEST[Tests + Coverage]
        UPLOAD_COV[Upload Coverage]
    end
    
    subgraph "Docker Workflow ğŸ³"
        CHECKOUT_D[Checkout Code]
        BUILDX[Setup Docker Buildx]
        LOGIN[Login to GHCR]
        META[Extract Metadata]
        BUILD_DEV[Build Development Image]
        BUILD_PROD[Build Production Image]
        PUSH_IMG[Push to ghcr.io]
    end
    
    subgraph "Train Workflow"
        CHECKOUT2[Checkout Code]
        SETUP2[Setup Python 3.10]
        DOWNLOAD[Download Data]
        TRAIN_EXEC[Train Model]
        SAVE_MODEL[Save Model Artifact]
    end
    
    subgraph "Evaluate Workflow"
        CHECKOUT3[Checkout Code]
        SETUP3[Setup Python 3.10]
        LOAD_MODEL[Load Model Artifact]
        EVAL_EXEC[Evaluate Model]
        SAVE_RESULTS[Save Results]
        COMMENT[Comment on PR]
    end
    
    %% CI Flow
    PUSH --> CHECKOUT1
    CHECKOUT1 --> SETUP1 --> LINT --> TEST --> UPLOAD_COV
    
    %% Docker Flow
    PUSH --> CHECKOUT_D
    TAG --> CHECKOUT_D
    CHECKOUT_D --> BUILDX --> LOGIN --> META
    META --> BUILD_DEV --> PUSH_IMG
    TAG -.only for tags.-> BUILD_PROD
    BUILD_PROD --> PUSH_IMG
    
    %% Train Flow
    MANUAL --> CHECKOUT2
    SCHEDULE --> CHECKOUT2
    CHECKOUT2 --> SETUP2 --> DOWNLOAD --> TRAIN_EXEC --> SAVE_MODEL
    
    %% Evaluate Flow
    SAVE_MODEL -.triggers.-> CHECKOUT3
    CHECKOUT3 --> SETUP3 --> LOAD_MODEL --> EVAL_EXEC --> SAVE_RESULTS --> COMMENT
    
    style PUSH fill:#bbdefb
    style MANUAL fill:#c8e6c9
    style SCHEDULE fill:#fff9c4
    style TAG fill:#f8bbd0
    style LINT fill:#ffccbc
    style TEST fill:#ffccbc
    style BUILD_DEV fill:#4A90E2
    style BUILD_PROD fill:#1565C0
    style PUSH_IMG fill:#4A90E2
    style TRAIN_EXEC fill:#c5e1a5
    style EVAL_EXEC fill:#ce93d8
```

### Workflows Activos

| Workflow | Trigger | DuraciÃ³n | Output |
|----------|---------|----------|--------|
| **CI - Testing and Linting** | Push/PR a main | ~50s | Test results + coverage |
| **Docker Build and Publish** | Push a main / Tags | ~1-2min | Docker image en GHCR |
| **Train Model** | Manual / Semanal | ~37s | Model artifact (.pkl) |
| **Evaluate Model** | DespuÃ©s de Train | ~44s | Metrics + visualizaciones |

## Componentes Principales

### 1. MÃ³dulo de Carga de Datos (`src/data_loader.py`)

**Responsabilidad**: Gestionar la carga y guardado de datasets

**Funciones principales**:

- `get_data_paths()`: Obtiene y crea directorios de datos
- `load_titanic_data()`: Carga datos raw del Titanic
- `save_processed_data()`: Guarda datos procesados
- `load_processed_data()`: Carga datos procesados

**CaracterÃ­sticas**:

- GestiÃ³n automÃ¡tica de rutas relativas
- CreaciÃ³n automÃ¡tica de directorios
- Manejo de errores con mensajes informativos

### 2. MÃ³dulo de Preprocesamiento (`src/preprocessing.py`)

**Responsabilidad**: Transformar datos raw en features listos para ML

**Clase principal**: `TitanicPreprocessor`

**Pipeline de transformaciÃ³n**:

1. **Feature Engineering**: Crear nuevas caracterÃ­sticas
   - `FamilySize`: TamaÃ±o de la familia
   - `IsAlone`: Indicador de viaje solo
   - `Title`: TÃ­tulo extraÃ­do del nombre (Mr, Mrs, Miss, etc.)

2. **ImputaciÃ³n de valores faltantes**:
   - Age: Mediana por grupo de tÃ­tulo
   - Fare: Mediana
   - Embarked: Moda

3. **CodificaciÃ³n**:
   - Label Encoding para variables categÃ³ricas
   - One-Hot Encoding para tÃ­tulos

4. **Escalado**:
   - StandardScaler para variables numÃ©ricas

**PatrÃ³n de diseÃ±o**: Fit-Transform (similar a scikit-learn)

- `fit_transform()`: Ajusta transformaciones y transforma datos de entrenamiento
- `transform()`: Aplica transformaciones ya ajustadas a datos nuevos

### 3. MÃ³dulo de Modelo (`src/model.py`)

**Responsabilidad**: Definir, crear, guardar y cargar modelos

**Modelos soportados**:

- `random_forest`: Random Forest Classifier (por defecto)
- `logistic_regression`: RegresiÃ³n LogÃ­stica
- `gradient_boosting`: Gradient Boosting Classifier

**Funciones principales**:

- `create_model()`: Factory para crear modelos con hiperparÃ¡metros
- `save_model()`: Serializar modelo con joblib
- `load_model()`: Deserializar modelo

**ConfiguraciÃ³n**: HiperparÃ¡metros predefinidos con posibilidad de override

### 4. MÃ³dulo de Entrenamiento (`src/train.py`)

**Responsabilidad**: Entrenar modelos y generar mÃ©tricas

**Proceso**:

1. Cargar datos raw
2. Preprocesar datos
3. Crear modelo
4. ValidaciÃ³n cruzada (k-fold)
5. Entrenamiento en conjunto completo
6. EvaluaciÃ³n en train y validaciÃ³n
7. Guardar modelo y mÃ©tricas

**Salidas**:

- Modelo entrenado en `models/`
- MÃ©tricas en `reports/training_metrics.json`

**Features especiales**:

- ValidaciÃ³n cruzada estratificada
- Feature importance para modelos basados en Ã¡rboles
- Argumentos de lÃ­nea de comandos

### 5. MÃ³dulo de EvaluaciÃ³n (`src/evaluate.py`)

**Responsabilidad**: Evaluar modelos y generar reportes

**MÃ©tricas calculadas**:

- Accuracy
- Precision
- Recall
- F1-Score
- ROC-AUC
- Confusion Matrix

**Visualizaciones generadas**:

- `confusion_matrix.png`: Matriz de confusiÃ³n
- `roc_curve.png`: Curva ROC
- `feature_importance.png`: Importancia de caracterÃ­sticas

**Salidas**:

- Resultados en `reports/evaluation_results.json`
- GrÃ¡ficas en `reports/*.png`

### 6. Scripts de Utilidad

#### `scripts/download_data.py`

- Descarga dataset del Titanic de fuentes confiables
- Fallback a mÃºltiples fuentes
- Split en train/test

#### `scripts/run_pipeline.py`

- Ejecuta el pipeline completo end-to-end
- Orquesta entrenamiento y evaluaciÃ³n

## Flujo de Datos

### TransformaciÃ³n de Datos

```mermaid
graph LR
    A[Datos Raw CSV] --> B[DataFrame Raw]
    B --> C[Feature Engineering]
    C --> D[ImputaciÃ³n]
    D --> E[CodificaciÃ³n]
    E --> F[SelecciÃ³n Features]
    F --> G[Escalado]
    G --> H[Datos Listos para ML]
    
    style A fill:#ffcdd2
    style H fill:#c8e6c9
    style C fill:#fff9c4
    style D fill:#fff9c4
    style E fill:#fff9c4
    style F fill:#fff9c4
    style G fill:#fff9c4
```

### Ciclo de Vida del Modelo

```mermaid
stateDiagram-v2
    [*] --> DatosRaw: Download
    DatosRaw --> DatosProcesados: Preprocessing
    DatosProcesados --> ModeloEntrenado: Training
    ModeloEntrenado --> ModeloEvaluado: Evaluation
    ModeloEvaluado --> ModeloEnProduccion: Deploy
    ModeloEnProduccion --> DatosRaw: Retraining
    ModeloEvaluado --> [*]: Rechazado
```

## Decisiones de DiseÃ±o

### 1. SeparaciÃ³n de Concerns

**DecisiÃ³n**: Dividir el cÃ³digo en mÃ³dulos independientes
**RazÃ³n**:

- Facilita testing unitario
- Permite reutilizaciÃ³n
- Mejora mantenibilidad
- Claridad en responsabilidades

### 2. Pipeline de Preprocesamiento Reusable

**DecisiÃ³n**: Usar clase `TitanicPreprocessor` con patrÃ³n fit-transform
**RazÃ³n**:

- Garantiza mismas transformaciones en train/test
- Evita data leakage
- Facilita deployment
- Consistente con scikit-learn

### 3. MÃºltiples Modelos Soportados

**DecisiÃ³n**: Factory pattern para crear diferentes tipos de modelos
**RazÃ³n**:

- ExperimentaciÃ³n fÃ¡cil
- ComparaciÃ³n de modelos
- Flexibilidad sin cambiar cÃ³digo

### 4. CI/CD Automatizado

**DecisiÃ³n**: Tres workflows separados (CI, Train, Evaluate)
**RazÃ³n**:

- CI rÃ¡pido para feedback inmediato
- Training independiente (puede ser costoso)
- EvaluaciÃ³n automÃ¡tica despuÃ©s de training
- SeparaciÃ³n de responsabilidades

### 5. Versionado de Artifacts

**DecisiÃ³n**: Guardar modelos y mÃ©tricas como artifacts
**RazÃ³n**:

- Trazabilidad
- Reproducibilidad
- Rollback posible
- Auditabilidad

### 6. ValidaciÃ³n Cruzada

**DecisiÃ³n**: K-fold cross-validation durante entrenamiento
**RazÃ³n**:

- EstimaciÃ³n robusta del rendimiento
- Reduce varianza
- Detecta overfitting

## Estructura de Directorios

```
practica_ci_cd/
â”‚
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/              # Workflows de GitHub Actions
â”‚       â”œâ”€â”€ ci.yml             # Testing y linting
â”‚       â”œâ”€â”€ train-model.yml    # Entrenamiento automÃ¡tico
â”‚       â””â”€â”€ evaluate-model.yml # EvaluaciÃ³n automÃ¡tica
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                   # Datos originales (git-ignored)
â”‚   â”‚   â”œâ”€â”€ train.csv
â”‚   â”‚   â””â”€â”€ test.csv
â”‚   â””â”€â”€ processed/             # Datos procesados (git-ignored)
â”‚       â”œâ”€â”€ train_processed.csv
â”‚       â”œâ”€â”€ test_processed.csv
â”‚       â””â”€â”€ val_processed.csv
â”‚
â”œâ”€â”€ src/                       # CÃ³digo fuente principal
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_loader.py        # Carga/guardado de datos
â”‚   â”œâ”€â”€ preprocessing.py      # Pipeline de preprocesamiento
â”‚   â”œâ”€â”€ model.py              # DefiniciÃ³n y gestiÃ³n de modelos
â”‚   â”œâ”€â”€ train.py              # Script de entrenamiento
â”‚   â””â”€â”€ evaluate.py           # Script de evaluaciÃ³n
â”‚
â”œâ”€â”€ scripts/                   # Scripts de utilidad
â”‚   â”œâ”€â”€ download_data.py      # Descarga del dataset
â”‚   â””â”€â”€ run_pipeline.py       # Pipeline end-to-end
â”‚
â”œâ”€â”€ tests/                     # Tests unitarios
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_preprocessing.py # Tests del preprocessor
â”‚   â””â”€â”€ test_model.py         # Tests del modelo
â”‚
â”œâ”€â”€ models/                    # Modelos entrenados (git-ignored)
â”‚   â””â”€â”€ titanic_model_*.pkl
â”‚
â”œâ”€â”€ reports/                   # Reportes y visualizaciones
â”‚   â”œâ”€â”€ training_metrics.json
â”‚   â”œâ”€â”€ evaluation_results.json
â”‚   â”œâ”€â”€ confusion_matrix.png  # (git-ignored)
â”‚   â”œâ”€â”€ roc_curve.png         # (git-ignored)
â”‚   â””â”€â”€ feature_importance.png # (git-ignored)
â”‚
â”œâ”€â”€ docs/                      # DocumentaciÃ³n detallada
â”‚   â”œâ”€â”€ modulos/              # Docs de mÃ³dulos Python
â”‚   â”œâ”€â”€ scripts/              # Docs de scripts
â”‚   â”œâ”€â”€ ci-cd/                # Docs de workflows
â”‚   â””â”€â”€ tests/                # Docs de testing
â”‚
â”œâ”€â”€ .gitignore                # Archivos ignorados por git
â”œâ”€â”€ requirements.txt          # Dependencias Python
â”œâ”€â”€ README.md                 # DocumentaciÃ³n principal
â”œâ”€â”€ ARQUITECTURA.md           # Este archivo
â””â”€â”€ GUIA_USO.md              # GuÃ­a de uso detallada
```

### PropÃ³sito de Cada Directorio

| Directorio | PropÃ³sito | Git Tracked |
|------------|-----------|-------------|
| `.github/workflows/` | AutomatizaciÃ³n CI/CD | âœ… |
| `data/raw/` | Datos originales descargados | âŒ |
| `data/processed/` | Datos transformados | âŒ |
| `src/` | CÃ³digo fuente principal | âœ… |
| `scripts/` | Scripts de utilidad | âœ… |
| `tests/` | Tests unitarios | âœ… |
| `models/` | Modelos serializados | âŒ |
| `reports/` | MÃ©tricas (JSON) y visualizaciones (PNG) | JSON: âœ…, PNG: âŒ |
| `docs/` | DocumentaciÃ³n detallada | âœ… |

## Patrones de DiseÃ±o Utilizados

### 1. Factory Pattern

**UbicaciÃ³n**: `src/model.py` - funciÃ³n `create_model()`
**Uso**: Crear diferentes tipos de modelos segÃºn parÃ¡metro

### 2. Template Method

**UbicaciÃ³n**: `src/preprocessing.py` - clase `TitanicPreprocessor`
**Uso**: Pipeline de preprocesamiento con pasos definidos

### 3. Dependency Injection

**UbicaciÃ³n**: MÃºltiples mÃ³dulos
**Uso**: Pasar dependencias como parÃ¡metros (e.g., rutas de archivos)

### 4. Pipeline Pattern

**UbicaciÃ³n**: `scripts/run_pipeline.py`
**Uso**: Orquestar mÃºltiples pasos en secuencia

## Consideraciones de ProducciÃ³n

### Escalabilidad

- **Actual**: DiseÃ±ado para datasets pequeÃ±os/medianos
- **Mejoras futuras**:
  - Integrar Dask/Spark para datos grandes
  - Procesamiento batch
  - ParalelizaciÃ³n de validaciÃ³n cruzada

### Monitoreo

- **Actual**: MÃ©tricas guardadas en JSON, logs en consola
- **Mejoras futuras**:
  - IntegraciÃ³n con MLflow/Weights & Biases
  - Dashboards de monitoreo
  - Alertas automÃ¡ticas

### Deployment

- **Actual**: Modelo guardado como archivo PKL
- **Mejoras futuras**:
  - API REST con FastAPI
  - ContainerizaciÃ³n con Docker
  - Deployment en cloud (AWS SageMaker, GCP AI Platform)

### Seguridad

- **Actual**: Sin autenticaciÃ³n/autorizaciÃ³n
- **Mejoras futuras**:
  - Secrets management
  - ValidaciÃ³n de inputs
  - AuditorÃ­a de acceso

## Referencias

- [DocumentaciÃ³n de mÃ³dulos](docs/modulos/)
- [DocumentaciÃ³n de workflows CI/CD](docs/ci-cd/)
- [GuÃ­a de uso detallada](GUIA_USO.md)
- [README principal](README.md)
